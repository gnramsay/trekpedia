{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0df20ede",
   "metadata": {},
   "source": [
    "# Trekpedia\n",
    "\n",
    "\n",
    "Writing a web-scraper to pull all `Star Trek(tm)` series data from Wikipedia.\n",
    "\n",
    "## Stage 2 - get episode data\n",
    "Create separate json files containing episode data for each Series.\n",
    "For now we will keep all seasons in one file but may break this into individual ones depending on how much data we finally grab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c1159ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# common setup...\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "\n",
    "# don't truncate Pandas.DataFrame cell contents when displaying.\n",
    "# pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e0313e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the data from stage 1 ...\n",
    "df = pd.read_json('output/star_trek_series_info_stage_1.json', orient='index')\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "51ca0d8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>url</th>\n",
       "      <th>season_count</th>\n",
       "      <th>episode_count</th>\n",
       "      <th>episodes_url</th>\n",
       "      <th>dates</th>\n",
       "      <th>logo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Original Series</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Star_Trek:_The_O...</td>\n",
       "      <td>3</td>\n",
       "      <td>79</td>\n",
       "      <td>https://en.wikipedia.org/wiki/List_of_Star_Tre...</td>\n",
       "      <td>September 8, 1966 - June 3, 1969</td>\n",
       "      <td>https://upload.wikimedia.org/wikipedia/commons...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Animated Series</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Star_Trek:_The_A...</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Star_Trek:_The_A...</td>\n",
       "      <td>September 8, 1973 - October 12, 1974</td>\n",
       "      <td>https://upload.wikimedia.org/wikipedia/commons...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Next Generation</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Star_Trek:_The_N...</td>\n",
       "      <td>7</td>\n",
       "      <td>178</td>\n",
       "      <td>https://en.wikipedia.org/wiki/List_of_Star_Tre...</td>\n",
       "      <td>September 28, 1987 - May 23, 1994</td>\n",
       "      <td>https://upload.wikimedia.org/wikipedia/commons...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Deep Space Nine</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Star_Trek:_Deep_...</td>\n",
       "      <td>7</td>\n",
       "      <td>176</td>\n",
       "      <td>https://en.wikipedia.org/wiki/List_of_Star_Tre...</td>\n",
       "      <td>January 4, 1993 - May 31, 1999</td>\n",
       "      <td>https://upload.wikimedia.org/wikipedia/commons...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Voyager</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Star_Trek:_Voyager</td>\n",
       "      <td>7</td>\n",
       "      <td>172</td>\n",
       "      <td>https://en.wikipedia.org/wiki/List_of_Star_Tre...</td>\n",
       "      <td>January 16, 1995 - May 23, 2001</td>\n",
       "      <td>https://upload.wikimedia.org/wikipedia/commons...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Enterprise</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Star_Trek:_Enter...</td>\n",
       "      <td>4</td>\n",
       "      <td>98</td>\n",
       "      <td>https://en.wikipedia.org/wiki/List_of_Star_Tre...</td>\n",
       "      <td>September 26, 2001 - May 13, 2005</td>\n",
       "      <td>https://upload.wikimedia.org/wikipedia/commons...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Discovery</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Star_Trek:_Disco...</td>\n",
       "      <td>4</td>\n",
       "      <td>55</td>\n",
       "      <td>https://en.wikipedia.org/wiki/List_of_Star_Tre...</td>\n",
       "      <td>September 24, 2017 - present</td>\n",
       "      <td>https://upload.wikimedia.org/wikipedia/commons...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Short Treks</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Star_Trek:_Short...</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Star_Trek:_Short...</td>\n",
       "      <td>October 4, 2018 - January 9, 2020</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Picard</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Star_Trek:_Picard</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Star_Trek:_Picard</td>\n",
       "      <td>January 23, 2020 - present</td>\n",
       "      <td>https://upload.wikimedia.org/wikipedia/commons...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Lower Decks</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Star_Trek:_Lower...</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Star_Trek:_Lower...</td>\n",
       "      <td>August 6, 2020 - present</td>\n",
       "      <td>https://upload.wikimedia.org/wikipedia/commons...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Prodigy</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Star_Trek:_Prodigy</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Star_Trek:_Prodigy</td>\n",
       "      <td>October 28, 2021 - present</td>\n",
       "      <td>https://upload.wikimedia.org/wikipedia/commons...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   name                                                url  \\\n",
       "0   The Original Series  https://en.wikipedia.org/wiki/Star_Trek:_The_O...   \n",
       "1   The Animated Series  https://en.wikipedia.org/wiki/Star_Trek:_The_A...   \n",
       "2   The Next Generation  https://en.wikipedia.org/wiki/Star_Trek:_The_N...   \n",
       "3       Deep Space Nine  https://en.wikipedia.org/wiki/Star_Trek:_Deep_...   \n",
       "4               Voyager   https://en.wikipedia.org/wiki/Star_Trek:_Voyager   \n",
       "5            Enterprise  https://en.wikipedia.org/wiki/Star_Trek:_Enter...   \n",
       "6             Discovery  https://en.wikipedia.org/wiki/Star_Trek:_Disco...   \n",
       "7           Short Treks  https://en.wikipedia.org/wiki/Star_Trek:_Short...   \n",
       "8                Picard    https://en.wikipedia.org/wiki/Star_Trek:_Picard   \n",
       "9           Lower Decks  https://en.wikipedia.org/wiki/Star_Trek:_Lower...   \n",
       "10              Prodigy   https://en.wikipedia.org/wiki/Star_Trek:_Prodigy   \n",
       "\n",
       "    season_count  episode_count  \\\n",
       "0              3             79   \n",
       "1              2             22   \n",
       "2              7            178   \n",
       "3              7            176   \n",
       "4              7            172   \n",
       "5              4             98   \n",
       "6              4             55   \n",
       "7              2             10   \n",
       "8              2             16   \n",
       "9              2             20   \n",
       "10             1             10   \n",
       "\n",
       "                                         episodes_url  \\\n",
       "0   https://en.wikipedia.org/wiki/List_of_Star_Tre...   \n",
       "1   https://en.wikipedia.org/wiki/Star_Trek:_The_A...   \n",
       "2   https://en.wikipedia.org/wiki/List_of_Star_Tre...   \n",
       "3   https://en.wikipedia.org/wiki/List_of_Star_Tre...   \n",
       "4   https://en.wikipedia.org/wiki/List_of_Star_Tre...   \n",
       "5   https://en.wikipedia.org/wiki/List_of_Star_Tre...   \n",
       "6   https://en.wikipedia.org/wiki/List_of_Star_Tre...   \n",
       "7   https://en.wikipedia.org/wiki/Star_Trek:_Short...   \n",
       "8     https://en.wikipedia.org/wiki/Star_Trek:_Picard   \n",
       "9   https://en.wikipedia.org/wiki/Star_Trek:_Lower...   \n",
       "10   https://en.wikipedia.org/wiki/Star_Trek:_Prodigy   \n",
       "\n",
       "                                   dates  \\\n",
       "0       September 8, 1966 - June 3, 1969   \n",
       "1   September 8, 1973 - October 12, 1974   \n",
       "2      September 28, 1987 - May 23, 1994   \n",
       "3         January 4, 1993 - May 31, 1999   \n",
       "4        January 16, 1995 - May 23, 2001   \n",
       "5      September 26, 2001 - May 13, 2005   \n",
       "6           September 24, 2017 - present   \n",
       "7      October 4, 2018 - January 9, 2020   \n",
       "8             January 23, 2020 - present   \n",
       "9               August 6, 2020 - present   \n",
       "10            October 28, 2021 - present   \n",
       "\n",
       "                                                 logo  \n",
       "0   https://upload.wikimedia.org/wikipedia/commons...  \n",
       "1   https://upload.wikimedia.org/wikipedia/commons...  \n",
       "2   https://upload.wikimedia.org/wikipedia/commons...  \n",
       "3   https://upload.wikimedia.org/wikipedia/commons...  \n",
       "4   https://upload.wikimedia.org/wikipedia/commons...  \n",
       "5   https://upload.wikimedia.org/wikipedia/commons...  \n",
       "6   https://upload.wikimedia.org/wikipedia/commons...  \n",
       "7                                                      \n",
       "8   https://upload.wikimedia.org/wikipedia/commons...  \n",
       "9   https://upload.wikimedia.org/wikipedia/commons...  \n",
       "10  https://upload.wikimedia.org/wikipedia/commons...  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a subset that only contains the seasons we want to work on.\n",
    "# df2 = pd.DataFrame(df.iloc[8]).transpose()\n",
    "df2 = df\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58211808",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to clean up strings - remove unicode and any brackets\n",
    "def clean_string(str, underscores=False, brackets=False, lowercase=False):\n",
    "    if underscores:\n",
    "        str = str.replace(\" \", \"_\").replace(\".\", \"_\").replace(\"__\", \"_\")\n",
    "    if brackets:\n",
    "        str = \"\".join(re.split(\"\\(|\\)|\\[|\\]\", str)[::2])\n",
    "    if lowercase:\n",
    "        str = str.lower()\n",
    "    return ' '.join(str.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e2b807c5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing : The Original Series\n",
      "  -> Using URL : https://en.wikipedia.org/wiki/List_of_Star_Trek:_The_Original_Series_episodes\n",
      "  -> Storing episodes to 'output/star_trek_series_0_the_original_series_episodes.json'\n",
      "  -> Processing season: 1 of 3\n",
      "  -> Processing season: 2 of 3\n",
      "  -> Processing season: 3 of 3\n",
      "  -> Done.\n",
      "\n",
      "Processing : The Animated Series\n",
      "  -> Using URL : https://en.wikipedia.org/wiki/Star_Trek:_The_Animated_Series\n",
      "  -> Storing episodes to 'output/star_trek_series_1_the_animated_series_episodes.json'\n",
      "  -> Processing season: 1 of 2\n",
      "  -> Processing season: 2 of 2\n",
      "  -> Done.\n",
      "\n",
      "Processing : The Next Generation\n",
      "  -> Using URL : https://en.wikipedia.org/wiki/List_of_Star_Trek:_The_Next_Generation_episodes\n",
      "  -> Storing episodes to 'output/star_trek_series_2_the_next_generation_episodes.json'\n",
      "  -> Processing season: 1 of 7\n",
      "  -> Processing season: 2 of 7\n",
      "  -> Processing season: 3 of 7\n",
      "  -> Processing season: 4 of 7\n",
      "  -> Processing season: 5 of 7\n",
      "  -> Processing season: 6 of 7\n",
      "  -> Processing season: 7 of 7\n",
      "  -> Done.\n",
      "\n",
      "Processing : Deep Space Nine\n",
      "  -> Using URL : https://en.wikipedia.org/wiki/List_of_Star_Trek:_Deep_Space_Nine_episodes\n",
      "  -> Storing episodes to 'output/star_trek_series_3_deep_space_nine_episodes.json'\n",
      "  -> Processing season: 1 of 7\n",
      "  -> Processing season: 2 of 7\n",
      "  -> Processing season: 3 of 7\n",
      "  -> Processing season: 4 of 7\n",
      "  -> Processing season: 5 of 7\n",
      "  -> Processing season: 6 of 7\n",
      "  -> Processing season: 7 of 7\n",
      "  -> Done.\n",
      "\n",
      "Processing : Voyager\n",
      "  -> Using URL : https://en.wikipedia.org/wiki/List_of_Star_Trek:_Voyager_episodes\n",
      "  -> Storing episodes to 'output/star_trek_series_4_voyager_episodes.json'\n",
      "  -> Processing season: 1 of 7\n",
      "  -> Processing season: 2 of 7\n",
      "  -> Processing season: 3 of 7\n",
      "  -> Processing season: 4 of 7\n",
      "  -> Processing season: 5 of 7\n",
      "  -> Processing season: 6 of 7\n",
      "  -> Processing season: 7 of 7\n",
      "  -> Done.\n",
      "\n",
      "Processing : Enterprise\n",
      "  -> Using URL : https://en.wikipedia.org/wiki/List_of_Star_Trek:_Enterprise_episodes\n",
      "  -> Storing episodes to 'output/star_trek_series_5_enterprise_episodes.json'\n",
      "  -> Processing season: 1 of 4\n",
      "  -> Processing season: 2 of 4\n",
      "  -> Processing season: 3 of 4\n",
      "  -> Processing season: 4 of 4\n",
      "  -> Done.\n",
      "\n",
      "Processing : Discovery\n",
      "  -> Using URL : https://en.wikipedia.org/wiki/List_of_Star_Trek:_Discovery_episodes\n",
      "  -> Storing episodes to 'output/star_trek_series_6_discovery_episodes.json'\n",
      "  -> Processing season: 1 of 4\n",
      "  => ERROR, need to investigate! ('NoneType' object has no attribute 'text') at line number: 42\n",
      "  -> Done.\n",
      "\n",
      "Processing : Short Treks\n",
      "  -> Using URL : https://en.wikipedia.org/wiki/Star_Trek:_Short_Treks\n",
      "  -> Storing episodes to 'output/star_trek_series_7_short_treks_episodes.json'\n",
      "  -> Processing season: 1 of 2\n",
      "  -> Processing season: 2 of 2\n",
      "  -> Done.\n",
      "\n",
      "Processing : Picard\n",
      "  -> Using URL : https://en.wikipedia.org/wiki/Star_Trek:_Picard\n",
      "  -> Storing episodes to 'output/star_trek_series_8_picard_episodes.json'\n",
      "  -> Processing season: 1 of 2\n",
      "  -> Processing season: 2 of 2\n",
      "  -> Done.\n",
      "\n",
      "Processing : Lower Decks\n",
      "  -> Using URL : https://en.wikipedia.org/wiki/Star_Trek:_Lower_Decks\n",
      "  -> Storing episodes to 'output/star_trek_series_9_lower_decks_episodes.json'\n",
      "  -> Processing season: 1 of 2\n",
      "  -> Processing season: 2 of 2\n",
      "  -> Done.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sys import exit\n",
    "\n",
    "\n",
    "# set up a filename template...\n",
    "FILE_TEMPLATE = 'output/star_trek_series_{}_{}_episodes.json'\n",
    "\n",
    "for row in df2.itertuples(index=True):  \n",
    "    \n",
    "    if row.name in ['Prodigy']:\n",
    "        continue\n",
    "\n",
    "    print(f'Processing : {row.name}')\n",
    "    filename = FILE_TEMPLATE.format(row.Index,row.name.replace(\" \", \"_\").lower())\n",
    "    print(f\"  -> Using URL : {row.episodes_url}\")\n",
    "    print(f\"  -> Storing episodes to '{filename}'\")\n",
    "    \n",
    "    season_final = dict()\n",
    "    season_all = dict()\n",
    "    \n",
    "    # get and parse the webpage...\n",
    "    result = requests.get(row.episodes_url)\n",
    "    bs = BeautifulSoup(result.text, 'lxml')\n",
    "\n",
    "    # wrap all this in a Try:Except block, there are a few series which need special handling...\n",
    "    try:\n",
    "        # find the episode summary table, will be the first table with the below classes in the document\n",
    "        summary_table = bs.find('table', attrs={'class': 'wikitable plainrowheaders'})\n",
    "\n",
    "        if summary_table:\n",
    "            summary_rows = summary_table.find('tbody').find_all('tr')[2:]\n",
    "        else:\n",
    "            print(\"   x No Summary Table found, currently skipping this Series ...\")\n",
    "            continue\n",
    "        \n",
    "        \n",
    "        for season in summary_rows:\n",
    "            season_data = dict()\n",
    "            # print(season.prettify())\n",
    "            link = season.find('th')\n",
    "            cells = season.find_all('td')         \n",
    "            \n",
    "            season_number = int(link.text)\n",
    "            \n",
    "            # exit the loop if we have processed the actual number of seasons. Usually this is not needed, \n",
    "            # however it is for the new series that are still in progress. \n",
    "            if season_number > row.season_count:\n",
    "                break\n",
    "            \n",
    "            print(f'  -> Processing season: {season_number} of {row.season_count}')\n",
    "            season_id = link.a['href'][1:]\n",
    "            season_data['total'] = clean_string(cells[1].text, brackets=True)\n",
    "            # get start/end data and remove unicode chars. \n",
    "            # Still need to remove the date in backets at the end of each\n",
    "            season_data['start'] = clean_string(\" \".join(cells[2].text.split()), brackets=True)\n",
    "            season_data['end'] = clean_string(\" \".join(cells[3].text.split()), brackets=True)\n",
    "            season_data['episodes'] = list()\n",
    "\n",
    "            # now get the actual episodes for this season...\n",
    "            section = bs.find('span', id=season_id)\n",
    "            table = section.findNext('table').find('tbody').find_all('tr')\n",
    "            \n",
    "            # split the headers out into a list, as they change between series and even seasons!\n",
    "            # at this time we also remove any unicode stuff \n",
    "            h = table[0].find_all('th')        \n",
    "            headers = [clean_string(x.text, underscores=True, brackets=True, lowercase=True) for x in h]\n",
    "            # remove the overall count as this is a TH not a TD and will skew the indexing later...\n",
    "            headers.remove('no_overall')\n",
    "            \n",
    "            # 'episodes' will consist of one row for each episode, except ds9 and voy who also put summary\n",
    "            # after each one and confuse things!\n",
    "            episodes = table[1:]\n",
    "        \n",
    "            episode_list = list()\n",
    "            # loop over each episode, getting the relevant data. We may grab more info in the future.\n",
    "            for episode in episodes:\n",
    "                episode_data = dict()\n",
    "                # protect the next operation - if the th is not found (ie tas, ds9, voy) just skip over this \n",
    "                # one as it is a summary...\n",
    "                try:\n",
    "                    episode_data['num_overall'] = clean_string(episode.find('th').text, brackets=True)\n",
    "                except AttributeError:\n",
    "                    continue\n",
    "                cells = episode.find_all('td')\n",
    "                episode_data['num_in_season'] = cells[headers.index('no_inseason')].text\n",
    "                \n",
    "                # need to do some tweaking, sometimes the first episode is in 2 parts\n",
    "                # need to detect this and split them. Alternative is to have a hard-coded list, as it\n",
    "                # happens very rarely.\n",
    "                \n",
    "                # get the required data using the header indexes, otherwise will mess up on ds9-s4 and later\n",
    "                # since they add new columns to the table.\n",
    "                episode_data['title'] = clean_string(cells[headers.index('title')].text.replace('\"',''), brackets=True)\n",
    "                try:\n",
    "                    # put these in try/except as some don't have episode links\n",
    "                    \n",
    "                    link_url = cells[headers.index('title')].a['href']\n",
    "                    if not \"cite_note\" in link_url:\n",
    "                        # make sure the only link is not a citation\n",
    "                        episode_data['link'] = f\"https://en.wikipedia.org{link_element}\"\n",
    "                except TypeError:\n",
    "                    # set the link url to an empty string...\n",
    "                    episode_data['link'] = ''\n",
    "                \n",
    "                episode_data['director'] = clean_string(cells[headers.index('directed_by')].text, brackets=True)\n",
    "\n",
    "                # air date needs a regex as is listed differently in later series...\n",
    "                airdate_idx = [i for i, item in enumerate(headers) if re.search('^original.*date$', item)][0]\n",
    "                episode_data['air_date'] = clean_string(cells[airdate_idx].text, brackets=True)\n",
    "                \n",
    "                episode_list.append(episode_data)\n",
    "                \n",
    "            # consolidate into a format suitable for writing to JSON\n",
    "            season_data['episodes'] = episode_list\n",
    "            season_all[season_number] = season_data\n",
    "            season_final['seasons'] = season_all\n",
    "    except AttributeError as e:\n",
    "        print(f\"  => ERROR, need to investigate! ({e}) at line number: {e.__traceback__.tb_lineno}\")\n",
    "    finally:\n",
    "       # write to json file...\n",
    "        with open (filename, 'w', encoding='utf-8') as f:\n",
    "            json.dump(season_final, f, ensure_ascii=False, indent=4)\n",
    "            print(f\"  -> Done.\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f92a1e0",
   "metadata": {},
   "source": [
    "## Current Bugs\n",
    "1. Some 2-part episodes have bad season and overall number due to table layout.\n",
    "2. [`ALL FIXED`] At least DS9 from season 4 and Voyager, Enterprise add a\n",
    "   'stardate' column which messes up the column count and therefore the\n",
    "   'Original Air Date' field. Voyager also adds 'featured character' to this\n",
    "   confusion. Later the air date field is renamed too.\n",
    "3. Discovery errors out after first season\n",
    "4. [`ALL FIXED`] From Short Treks to Lower Decks error out on line 76, more\n",
    "   formatting changes.\n",
    "5. Prodigy errors out at the start, this is because it has no Season Summary\n",
    "   table. We may want to change the way we get the data, using the\n",
    "   'wikiepisodetable' class directly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd6bba4",
   "metadata": {},
   "source": [
    "# Different Method test.\n",
    "Leaving this in as markdown for future reference, but the read_html function of Pandas is not really working well for these tables.\n",
    "\n",
    "```python\n",
    "FILE_TEMPLATE = 'output/star_trek_series_{}_{}_episodes.json'\n",
    "\n",
    "for row in df.itertuples(index=True):\n",
    "   \n",
    "    print(f'Processing : {row.name}')\n",
    "    filename = FILE_TEMPLATE.format(row.Index,row.name.replace(\" \", \"_\").lower())\n",
    "    print(f\"  -> Using URL : {row.episodes_url}\")\n",
    "    print(f\"  -> Storing episodes to '{filename}'\")\n",
    "    \n",
    "    season_final = dict()\n",
    "    season_all = dict()\n",
    "    \n",
    "    # get and parse the webpage...\n",
    "    result = requests.get(row.episodes_url)\n",
    "    bs = BeautifulSoup(result.text, 'lxml')\n",
    "    \n",
    "    # wrap all this in a Try:Except block, there are a few series which need special handling...\n",
    "    try:\n",
    "        # find the episode summary table, will be the first table with the below classes in the document\n",
    "        summary_table = bs.find('table', attrs={'class': 'wikitable plainrowheaders'})\n",
    "        \n",
    "        summary_rows = summary_table.find('tbody').find_all('tr')[2:]\n",
    "        \n",
    "        for season in summary_rows:\n",
    "            season_data = dict()\n",
    "            \n",
    "            link = season.find('th')\n",
    "            cells = season.find_all('td')         \n",
    "            \n",
    "            season_number = link.text\n",
    "            season_id = link.a['href'][1:]\n",
    "            season_data['total'] = cells[1].text\n",
    "            # get start/end data and remove unicode chars. \n",
    "            # Still need to remove the date in backets at the end of each\n",
    "            season_data['start'] = \" \".join(cells[2].text.split())\n",
    "            season_data['end'] = \" \".join(cells[3].text.split())\n",
    "            season_data['episodes'] = list()\n",
    "            \n",
    "            # now get the actual episodes for this season...\n",
    "            section = bs.find('span', id=season_id)\n",
    "            table = section.findNext('table')\n",
    "            \n",
    "            table_data = pd.read_html(str(table), parse_dates=True)\n",
    "            print(table_data)\n",
    "            print(\"[>----------------<]\")\n",
    "            \n",
    "    except AttributeError as e:\n",
    "        print(f\"  => Error, need to investigate! ({e}) at line number: {e.__traceback__.tb_lineno}\")\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1f975eca457c413ecfffa3b26ee5bfb96b52c7a248ca235d083f835b868b010c"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
